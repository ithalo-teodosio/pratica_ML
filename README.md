# ğŸ” Projeto de Machine Learning â€“ Hackaton Unifacisa

RepositÃ³rio contendo a resoluÃ§Ã£o das **9 questÃµes prÃ¡ticas de Machine Learning** propostas no Hackaton da Unifacisa. Os desafios envolvem classificaÃ§Ã£o, regressÃ£o, clusterizaÃ§Ã£o e avaliaÃ§Ã£o de modelos com foco em problemas reais de negÃ³cio, saÃºde, seguranÃ§a e mercado financeiro.

---

## âœ… QuestÃµes Respondidas

### ğŸ§  QuestÃ£o 1 - RegressÃ£o Linear (PreÃ§o de ImÃ³veis)
**Tema:** Prever o preÃ§o de casas com base em variÃ¡veis como tamanho, nÃºmero de quartos e localizaÃ§Ã£o.
- ğŸ“¦ Bibliotecas: `pandas`, `numpy`, `matplotlib`, `scikit-learn`
- ğŸ¤– Modelo: `LinearRegression`
- ğŸ“Š AvaliaÃ§Ã£o: RÂ² Score
- ğŸ“ˆ Resultado: Modelo simples, mas com bom poder preditivo.

### ğŸ” QuestÃ£o 2 - DetecÃ§Ã£o de Fraudes com Random Forest
**Tema:** Identificar transaÃ§Ãµes fraudulentas com base em caracterÃ­sticas transacionais.
- ğŸ“¦ Bibliotecas: `make_classification`, `pandas`, `StandardScaler`, `RandomForestClassifier`, `classification_report`
- ğŸ§ª Dataset sintÃ©tico com 5% de fraudes
- ğŸ¤– Modelo: `RandomForestClassifier`
- âœ… AcurÃ¡cia: 97%
- ğŸ§® F1-Score para fraudes: 0.65
- ğŸ”§ Melhorias possÃ­veis: balanceamento de dados, SMOTE, otimizaÃ§Ã£o de hiperparÃ¢metros

### ğŸ›ï¸ QuestÃ£o 3 - SegmentaÃ§Ã£o de Clientes de E-commerce (K-Means)
**Tema:** Agrupar clientes com base em comportamento de compras.
- ğŸ“¦ Bibliotecas: `pandas`, `numpy`, `matplotlib`, `KMeans`, `StandardScaler`
- ğŸ“Š VariÃ¡veis: quantidade de compras, valor gasto, frequÃªncia
- ğŸ“Œ TÃ©cnica: `KMeans` + `Elbow Method`
- ğŸ“ˆ Clusters: 4 grupos definidos
- ğŸ” PadrÃµes encontrados:
  - Cluster 0: Baixo gasto, baixa frequÃªncia
  - Cluster 1: Alto gasto, baixa frequÃªncia
  - Cluster 2: Baixo gasto, alta frequÃªncia
  - Cluster 3: Alto gasto, alta frequÃªncia

### â¤ï¸ QuestÃ£o 4 - ClusterizaÃ§Ã£o de Dados de SaÃºde (PCA + K-Means)
**Tema:** Agrupar pacientes por perfil clÃ­nico (idade, IMC, glicose, colesterol, pressÃ£o)
- ğŸ“¦ Bibliotecas: `pandas`, `numpy`, `matplotlib`, `seaborn`, `StandardScaler`, `PCA`, `KMeans`, `silhouette_score`
- ğŸ§¬ TÃ©cnica de visualizaÃ§Ã£o: `PCA`
- ğŸ¤– ClusterizaÃ§Ã£o: `KMeans`, K=3
- ğŸ“Š InterpretaÃ§Ã£o dos grupos:
  - Cluster 0: Alto risco metabÃ³lico
  - Cluster 1: Perfil saudÃ¡vel
  - Cluster 2: Idosos com pressÃ£o/colesterol elevados
- ğŸ” Silhouette Score: 0.46

### ğŸ“ˆ QuestÃ£o 5 - PrevisÃ£o de AÃ§Ãµes com RegressÃ£o Linear
**Tema:** Prever preÃ§os de aÃ§Ãµes com base em volume e mÃ©dia mÃ³vel
- ğŸ“¦ Bibliotecas: `pandas`, `numpy`, `matplotlib`, `scikit-learn`
- ğŸ¤– Modelo: `LinearRegression`
- ğŸ§® Score RÂ²: 0.72
- ğŸ’¬ ObservaÃ§Ã£o: AplicaÃ§Ã£o introdutÃ³ria, modelo simples

### ğŸ¯ QuestÃ£o 6 - ClassificaÃ§Ã£o BinÃ¡ria de DoenÃ§a (Logistic Regression)
**Tema:** Prever presenÃ§a de doenÃ§a cardÃ­aca com variÃ¡veis clÃ­nicas
- ğŸ“¦ Bibliotecas: `LogisticRegression`, `train_test_split`, `accuracy_score`, `recall_score`
- ğŸ¤– Modelo: `LogisticRegression`
- âœ… AcurÃ¡cia: 86%
- ğŸ“¢ Recall: 88% (boa detecÃ§Ã£o de positivos)

### ğŸ’¡ QuestÃ£o 7 - ClassificaÃ§Ã£o Multiclasse (Ãrvore de DecisÃ£o)
**Tema:** Classificar tipos de consumidores com base em perfil de consumo
- ğŸ“¦ Bibliotecas: `DecisionTreeClassifier`, `pandas`, `train_test_split`
- ğŸ¤– Modelo: `DecisionTreeClassifier`
- âœ… Accuracy: 84%
- âš ï¸ ObservaÃ§Ã£o: PossÃ­vel overfitting; ideal testar Random Forest ou poda

### ğŸ“Š QuestÃ£o 8 - ClusterizaÃ§Ã£o com DBSCAN
**Tema:** Agrupar padrÃµes de uso de aplicativo (nÃºmero de acessos, tempo de uso, etc.)
- ğŸ“¦ Bibliotecas: `DBSCAN`, `StandardScaler`, `matplotlib`, `pandas`, `numpy`
- ğŸ” TÃ©cnica: `DBSCAN` (baseado em densidade)
- ğŸ§© Clusters encontrados: 3 grupos principais + outliers
- ğŸš€ Vantagem: detecta automaticamente ruÃ­dos nos dados

### ğŸ§¬ QuestÃ£o 9 - ClassificaÃ§Ã£o com SVM (CÃ¢ncer de Mama)
**Tema:** DiagnÃ³stico de cÃ¢ncer com base em caracterÃ­sticas celulares
- ğŸ“¦ Bibliotecas: `SVC`, `StandardScaler`, `classification_report`
- ğŸ¤– Modelo: `Support Vector Classifier`
- âœ… Accuracy: 93%
- ğŸ’¡ ConclusÃ£o: Ã“timo desempenho apÃ³s normalizaÃ§Ã£o dos dados

---

## âš™ï¸ Tecnologias Usadas
- ğŸ Python 3
- ğŸ§° Bibliotecas principais:
  - `pandas`, `numpy`, `matplotlib`, `seaborn`
  - `scikit-learn`: modelos de ML, mÃ©tricas, clustering

---

## ğŸ“ Estrutura dos Arquivos
```
ğŸ“‚ ML_Hackaton_Unifacisa
â”œâ”€â”€ Q1_regressao_linear_imoveis.ipynb
â”œâ”€â”€ Q2_fraude_cartao.ipynb
â”œâ”€â”€ Q3_kmeans_clientes.ipynb
â”œâ”€â”€ Q4_clusters_saude.ipynb
â”œâ”€â”€ Q5_regressao_acoes.ipynb
â”œâ”€â”€ Q6_classificacao_doencas.ipynb
â”œâ”€â”€ Q7_arvore_multiclasse.ipynb
â”œâ”€â”€ Q8_dbscan_uso_app.ipynb
â”œâ”€â”€ Q9_svm_cancer.ipynb
â””â”€â”€ README.md
```

---

## ğŸ‘¤ Autor
**Ithalo TeodÃ³sio Nascimento**
- Estudante de AnÃ¡lise e Desenvolvimento de Sistemas â€“ Unifacisa
- GitHub: [@ithalo-teodosio](https://github.com/ithalo-teodosio)

---

ğŸ“¢ *Este projeto foi desenvolvido como parte do Hackaton de Machine Learning da Unifacisa, com foco em aplicaÃ§Ãµes reais de IA e ciÃªncia de dados.*

